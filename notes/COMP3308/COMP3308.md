# COMP3308 Notes -  By Ian Cleasby

## Week 1: Problem Solving and Search

- HWK : 6%
- Quiz  (week 4) 14%
- Assignment 1 (Week 9)
- Assignment 2 (Week 13)
- Exam 45%

### Search Problem Formulation

1. Initial State
2. Goal State
3. Operators = actions
4. Path cost function - assigns a numerical value to each path

Solution - a path from the intial to a goal state.

State space: all states reachable from the initial state by operators


### Nodes vs States
- A *node* is different than a *state*
- A *node*:
	- represents a state
	- is a data structure used in the search tree
	- includes parent children and other relevant information .eg *depth* and *path cost g*

### Search Strategies
- A search strategy defines which node from the fringe is most promising and should be expanded next
- We will keep the nodes in the fringe ordered based on the search strategy and always expand the first one (i.e the best one)
- **Evaluation criteria**:
	- *Completeness* - is it guaranteed to find a solution if one exists?
	- *Optimality* - is it guaranteed to find an *optimal (least cost path)* solution?
	- **Time Complexity* - how long does it take to find the solution? *(measured as number of generated nodes)*
	- **Space Complexity* - What is the maximu number of nodes in memory?
- Time and space complexity are measured in terms of:
	- *b* - max branching factor of the search tree *(assume finite)*
	- *d* - depth of the optimal *(least cost)* solution
	- *m* - maximum depth of the state space *(can be finite or not finite.)*

### Uniformed (Blind) Search Strategies

- Generate children in a systematic way *i.e left -> right*
- Know if a child node is a goal or non-goal node
- Do not know if one non-goal child is better *(more promising)*
than another one. By contrast, informed *(heuristic)* search strategies know this

#### Breadth-First Search *(BFS)*
- Expands the *shallowest* unexpanded node
- *Implementation:* insert children at the end of the fringe
- **Complete:** Yes (if branching factor b is finite, assume so)
- **Optimal:** Not optimal in general; Yes, if step cost is the same *(e.g: =1)*
- **Time:** generated nodes = $1+b+b^2+b^3+b^4+...+b^d = O(b^d)$
- **Space:** $O(b^d)$ - every node stored in memory *(time and space grow exponentially, which is a problem)*

#### Uniform Cost Search *(UCS)*
- UCS considers the step cost. It expands the *least-cost* unexpanded node - the node *n* with the *lowest path cost g(n) from the initial state.*
- *Implementation:* insert nodes in the fringe in order of increasing path cost from the root
- **Complete:** Yes
- **Optimal:** Yes
- **Time:** nodes with $g \leq O(b^d)$ - Dependent on Path Cost
- **Space:** nodes with $g \leq O(b^d)$ - Dependent on Path Cost

#### Depth-First Search *(DFS)*
- Expands *deepest* unexpanded node
- *Implementation:* insert children at the front of the fringe
- **Complete:** No, fails in infinite depth spaces
- **Optimal:** No, may finsd solution longer than the OPT
- **Time:**  $1+b+b^2+b^3+b^4+...+b^m = O(b^m)$
	- higher than BFS as m>>d *(m=max depth, d= least cost solution depth)*
- **Space: **$O(bm)$, linear, once a node has been expanded it can be removed from memory once all descendents have been fully explored

#### Iterative Deepening Search *(IDS)*
- Trying all possible depth limits in turn *(0,1,2, etc)* and applying DFS
- Tries to combine benefits of DFS *(low memory)* and BFS *(completeness if b is finite and optimality if step costs are the same)* by repeated DFS searches with increased Depth
- **Complete:** *BFS:* Yes, *DFS:* Yes, if *m* is finite, otherwise no
- **Optimal:** No, *unless step cost = 1 *DFS:* No*
- **Time:**  $(d+1)b^0+db^1+(d-1)b^2+...+b^d = O(b^d)$  *DFS:* $O(b^m)$
- **Space: **$O(bd)$, linear
- Can be modified to explore uniform-cost tree

------------------------------
### Week 2a: Informed Search Strategies
- Informed Search Strategies use problem-specific knowledge to select the order of node expansion
	- They can compare non-goal nodes - they know if one non goal node is better than another one
	- They are typically more efficient

#### Greedy Search *(GS)*
- *h* value as an evaluation function *(h for heuristic)*
- The *h(n)* for a node *n* is the estimated cost from node *n* to a *goal node*
- Note: *h* value of goal node is 0
- *Implementation:* expands the node with the smallest *h*
	- The node that appears to be closest to a goal
- Thus: GS minimizes *h* to the estimated cost to a goal
- **Complete:** *DFS:* Yes, if (*m* is finite), otherwise no *(infinite loops)*
- **Optimal:** No
- **Time:** $O(b^m)$, but a good heuristic can give dramatic improvement
- **Space: ** $O(b^m)$, keeps every node in memory

#### A* Search

- UCS minimizes the cost so far *g(n)*
- GS minimizes the estimated cost to the goal *h(n)*
- A* combines UCS and GS
- *Evaluation function:* $f(n) = g(n)+h(n)$
	- *g(n)* = cost so far to reach *n*
	- *h(n)* = estimated cost from n to the goal
	- *f(n) = estimated total cost of through *n* to the goal
- **Complete:** Yes, unless there are infinitely many nodes with $ f \leq f(G)$, *G* - optimal goal state
- **Optimal:** Yes, with admissible heuristic
- **Time:** Exponential $O(b^d)$
- **Space: ** Exponential, keeps all nodes in memory
- *Note:* Both time and space are problems for A* but space is the bigger problem - A* runs out of space long before it runs out of time; **Solution:** *Iterative Deepening A\** *(IDA\*)* or *Simplified Memory Bounded A\** *(SMBA\*)*

- If *h(n)* is **admissible**, *A\** is optimal
- If *h(n)* is **consistent**, *A\** is optimally efficient - *A\** will expand less or equal number of nodes than any other optimal algorithm using *h(n)*

##### Admissible heuristic
- A heuristic *h(n)* is admissible if for every node *n*:
	- $h(n) \leq h^\*(n)$ where $h^\*(n)$ is the true cost to reach a goal from *n*

##### Consistent (monotonic) Heuristic
- Consider a pair of nodes $n_i$ and $n_j$, where $n_i$ is the parent of $n_j$
- h is a consistent *(monotonic)* heuristic, if for all such pairs in the search
graph the following triangle inequality is satisfied:
	- $h(n_i) \leq cost(n_i,n_j)+ h(n_j)$ for all $n$

In other words:

- => $h(n_j) \geq h(n_i)- cost(n_i,n_j)$ , i.e. along any path our estimate of the
remaining cost to the goal cannot decrease by more than the arc cost

##### Admissibility and Consistency
- If a heuristic is consistent, it is also admissible
	- $consistent \Rightarrow admissible$
- If a heuristic is admissible, there is no guarantee that it is consistent
	- $admissible \nRightarrow consistent$
-----
### Week 2b: Local Search Algorithms

#### Optimisation Problems
- Each state has a value *v*
- *Goal:* find the optimal state
	- the state with the highest or lowest *v* score (depending on what is desirable, *max* or *min*)
- *Solution:* the state *(Path is not important)*
- A large number of states $\Rightarrow$ can't be enumerated
	- $\Rightarrow$ We can't apply the previous algorithms - too expensive

#### V-value Landscape
- Each state has a value *v* that we can compute
- This value is defined by a heuristic *evaluation function (objective function)*
- *Goal - 2 variations depending on the task:*
	- find the state with the highest value *(global max)*
	- find the state with the lowest value *(global min)*
- *Complete local search* - finds a goal state if one exists
- *Optimal local search* - finds the state associated with the global max/min  

#### Hill-Climbing Algorithm
- *Idea:* Keep only a single state in memory, try to improve it
** Variations:**
##### *Steepest ascent* - the goal is the max value
- *Idea:* move around trying to find the highest peak
	- Store only of the current state
	- Do not look a head beyond the immediate neighbours of the current state
	- If a neighbouring state is better, move to it & continue, otherwise stop

##### *Steepest descent* - the goal is the min value
1. Set current node *n* to the initial state *s* *(given or randomly selected)*
2. Generate the successors of *n*. Select the best sucessor $n_{best}$; it is the sucessor with the best *v* score, *v(best)* (i.e lowest score)
3. If $v(best) > v(n)$, return *n*
	- Else set *n* to $n_{best}$. Go to step 2 - if better accept the child and keep searching

#### Beam Search
- tracks k states instead of 1

##### Version 1: 
- Starts with *1 given state*
- At each level: generate all successors of the given state
- If any one is a goal state -> *stop*
	- else select the *k* best successors from the list and go to the next level  

##### Version 2:
- Starts with *k randomly generated states*
- At each level: generate all successors of all *k* states
- If any one is a goal state -> *stop*
	- else select the *k* best successors from the list and go to the next level

##### Beam Search with *A\**
- Memory is a big problem for *A\**
- *Idea:* keep only the best *k* nodes in the fringe, *i.e use a priority queue of size k*

*Advantage:* memory efficient
*Disadvantage:* neither complete, nor optimal

#### Simulated Annealing 
1. Set current node *n* to the initial state *s*. 
	- Randomly select *m*, one of *n*'s successors
2. If *v(m)* is better than *v(n)*, *v(n), n=m* // accept the child *m*
	- Else *n=m* with a probability *p* // accept the child *m* with probability *p*
3. Go to step 2 until a predefined number of iterations is reached or the state reached *(solution)*

##### Probability p
- Assume that we are looking for a *min*
- **Main Idea:**
	1.*p* decreases exponentially with the badness of the child *(move)* and
	2. bad children *(moves)* are more likely to be allowed at the beginning than at the end
- *nominator:* shows how good the child *m* is
- *deminator:* parameter *T* that decreases *(anneals)* over time based on a *schedule*
#### Genetic Algorithms
- Each state is called an *individual*. It is coded as a string
- Each state *n* has a fitness score *f(n)* (evaluation function). The higher the value , the better the state.
- *Goal:* starting with *k* randomly generated individuals, find the optimal state
- Successors are produced by selection, crossover and mutation
- At any time keeps a fixed number of states *(the population)*

##### Properties:
- Combine uphill tendency with random exploration and exchange information among parallel threads; the main advantage comes from crossover
- Success depends on the representation (encoding)
- Easy to implement
- Not *complete*, not *optimal*